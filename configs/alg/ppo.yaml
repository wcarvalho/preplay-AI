ALG: 'ppo'

# EXPERIMENT PARAMS
NUM_SEEDS: 1
SEED: 1

# logging
#MAX_EPISODE_LOG_LEN: 40

# RUN PARAMS
NUM_ENV_SEEDS: 0
TOTAL_TIMESTEPS: 1_000_000_000  # 1e9
NUM_ENVS: 1024
EVAL_STEPS: 100
EVAL_EPISODES: 100
#LEARNER_LOG_PERIOD: 500
#LEARNER_EXTRA_LOG_PERIOD: 5_000
#EVAL_LOG_PERIOD: 25
#EVAL_LOG_PERIOD_ACTOR: 0
#GRADIENT_LOG_PERIOD: 5_000

# NEURAL NET PARAMS
LAYER_SIZE: 512
#ACTIVATION: 'tanh'

# ALGO PARAMS
TRAINING_INTERVAL: 64
LR: 0.0002  # 2e-4
ANNEAL_LR: True
UPDATE_EPOCHS: 4
NUM_MINIBATCHES: 8
GAMMA: 0.99
GAE_LAMBDA: 0.8
CLIP_EPS: 0.2
ENT_COEF: 0.01
VF_COEF: 0.5
MAX_GRAD_NORM: 1.0

# ENVIRONMENT PARAMS
#USE_OPTIMISTIC_RESETS: True
OPTIMISTIC_RESET_RATIO: 16

# DEBUG AND TESTING
DEBUG: False
USE_WANDB: True
TEST_NUM_ENVS: 10_000  # Added based on craftax_ppo_trainer.py needs